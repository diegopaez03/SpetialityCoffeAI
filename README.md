---

```markdown
# â˜• Proyecto Integrador PI5 â€“ CafÃ© de Especialidad  
### IntegraciÃ³n de un LLM Open Source con un Grafo de Conocimiento (Neo4j + LangChain + FastAPI)

---

## ğŸ“˜ DescripciÃ³n general

Este proyecto implementa un **sistema inteligente de consulta sobre cafÃ© de especialidad**, integrando:

- **Neo4j AuraDB** (grafo de conocimiento del dominio â€œcafÃ© de especialidadâ€)  
- **LangChain + Ollama** con un modelo **LLM open source (`gpt-oss:120b-cloud`)**  
- **FastAPI + HTML minimalista** como interfaz web de chat

El objetivo es responder preguntas contextualizadas sobre cafÃ©s, mÃ©todos de preparaciÃ³n, molienda, recetas, perfiles sensoriales y procesos de tueste, combinando **razonamiento semÃ¡ntico del LLM** con **recuperaciÃ³n estructurada desde el grafo**.

---

## ğŸ¯ Objetivo de la actividad

> Actividad PI5 â€“ Unidad 4  
> â€œIntegraciÃ³n de un LLM Open Source con Grafo de Conocimientoâ€

El propÃ³sito es integrar un modelo de lenguaje open source con un grafo de conocimiento Neo4j para responder preguntas en lenguaje natural sobre un dominio definido por el estudiante.

Este dominio seleccionado es **CafÃ© de Especialidad**, abarcando entidades como cafÃ©s, orÃ­genes, variedades, procesos, mÃ©todos de preparaciÃ³n, molienda y recetas.

---

## ğŸ§© Arquitectura general

```

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Interfaz HTML   â”‚
    â”‚ (index.html)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (POST /chat)
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FastAPI (main)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LLM Chain (LangChain + OllamaLLM)         â”‚
    â”‚  - Interpreta pregunta en lenguaje natural â”‚
    â”‚  - Genera consulta Cypher                 â”‚
    â”‚  - Fusiona respuesta del grafo y del LLM  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Neo4j AuraDB    â”‚
    â”‚ (grafo del cafÃ©) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```

---

## ğŸ“‚ Estructura del proyecto

```

pi5-cafe/
â”œâ”€ .env                     # credenciales y configuraciÃ³n local
â”œâ”€ requirements.txt         # dependencias
â”‚
â”œâ”€ neo4j/
â”‚  â”œâ”€ seed.cypher           # script para poblar el grafo
â”‚  â””â”€ graph_service.py      # conexiÃ³n y utilidades para Neo4j
â”‚
â”œâ”€ llm/
â”‚  â”œâ”€ llm_service.py        # configuraciÃ³n del modelo Ollama LLM
â”‚  â””â”€ graph_qa.py           # cadena LLM â†” Neo4j (GraphCypherQAChain)
â”‚
â”œâ”€ api/
â”‚  â”œâ”€ main.py               # API FastAPI + endpoint /chat
â”‚  â””â”€ templates/
â”‚     â””â”€ index.html         # interfaz web de chat
â”‚
â””â”€ README.md

````

---

## âš™ï¸ ConfiguraciÃ³n del entorno

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/tuusuario/pi5-cafe.git
cd pi5-cafe
````

### 2ï¸âƒ£ Crear entorno virtual

```bash
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configurar variables de entorno

Crea un archivo `.env` en la raÃ­z con tus credenciales:

```bash
# Neo4j AuraDB
NEO4J_URI=neo4j+s://<tu-uri>.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=<tu_password>

# Ollama LLM
CLOUD_OLLAMA_URL=http://localhost:11434
LLM_MODEL=gpt-oss:120b-cloud
TEMPERATURE=0.2

# Token simple para la API
API_TOKEN=changeme
```

> ğŸ”’ No subas el `.env` al repositorio si incluye contraseÃ±as reales.

---

## â˜ï¸ Cargar el grafo en Neo4j AuraDB

1. EntrÃ¡ al **Neo4j Aura Console** o **Neo4j Browser**.
2. CopiÃ¡ el contenido de `neo4j/seed.cypher`.
3. EjecutÃ¡ todo el script (crea nodos, relaciones y constraints).

Para verificar:

```cypher
MATCH (n) RETURN labels(n) AS etiquetas, count(*) AS cantidad ORDER BY cantidad DESC;
```

DeberÃ­as ver al menos 10 tipos de nodos con relaciones.

---

## ğŸ¤– Probar el servicio LLM

Antes de la integraciÃ³n completa, probÃ¡ la comunicaciÃ³n con el modelo:

```bash
python llm/llm_service.py
```

DeberÃ­as obtener una respuesta corta como:

```
El pour-over es un mÃ©todo manual de filtrado de cafÃ©.
```

---

## ğŸ”— Ejecutar la API

IniciÃ¡ la aplicaciÃ³n:

```bash
uvicorn api.main:app --reload
```

Luego abrÃ­ en el navegador:

ğŸ‘‰ **[http://127.0.0.1:8000/](http://127.0.0.1:8000/)**

---

## ğŸ’¬ Interfaz web

La interfaz es un chat simple que permite ingresar preguntas sobre el dominio de cafÃ©.
Ejemplo:

```
Â¿QuÃ© molido recomienda el grafo para preparar pour-over?
```

El sistema:

1. EnvÃ­a la pregunta al endpoint `/chat`
2. El LLM genera una consulta Cypher interna
3. Se ejecuta contra Neo4j
4. El modelo produce una respuesta contextualizada en lenguaje natural

---

## ğŸ§  Ejemplos de preguntas

| Pregunta                                                          | Tipo de razonamiento                   | Ejemplo de respuesta                                                         |
| ----------------------------------------------------------------- | -------------------------------------- | ---------------------------------------------------------------------------- |
| Â¿QuÃ© molido recomienda el grafo para preparar pour-over?          | RelaciÃ³n MÃ©todoâ€“Molido                 | â€œEl mÃ©todo pour-over requiere molido medio para una extracciÃ³n equilibrada.â€ |
| Â¿CuÃ¡les son las notas sensoriales del cafÃ© EtiopÃ­a Washed Sidamo? | Consulta de propiedades y relaciones   | â€œPresenta notas florales y cÃ­tricas, propias de cafÃ©s etÃ­opes de altura.â€    |
| Mostrame una receta para espresso con su ratio y temperatura.     | RecuperaciÃ³n de nodo `Receta` y `Agua` | â€œRatio 1:2, 93Â°C, tiempo 28 segundos, usando agua filtrada.â€                 |

---

## ğŸ§± Modelo conceptual (simplificado)

```text
(Cafe) -[:ES_DE_ORIGEN]-> (Origen)
(Cafe) -[:ES_DE_VARIEDAD]-> (Variedad)
(Cafe) -[:PROCESADO_COMO]-> (Proceso)
(Cafe) -[:TOSTADO_POR]-> (Tostador)
(Cafe) -[:TIENE_PERFIL]-> (PerfilSensorial)
(Metodo) -[:REQUIERE_MOLIDO]-> (Molido)
(Metodo) -[:IDEAL_PARA]-> (Cafe)
(Receta) -[:PARA_METODO]-> (Metodo)
(Receta) -[:USA_AGUA]-> (Agua)
```

---

## ğŸ“Š TecnologÃ­as utilizadas

| Componente                | TecnologÃ­a                                          | DescripciÃ³n                                        |
| ------------------------- | --------------------------------------------------- | -------------------------------------------------- |
| **Grafo de conocimiento** | [Neo4j AuraDB](https://neo4j.com/cloud/aura/)       | Base de datos de grafos administrada               |
| **Modelo LLM**            | [Ollama](https://ollama.com) + `gpt-oss:120b-cloud` | Modelo open source de lenguaje natural             |
| **IntegraciÃ³n**           | [LangChain](https://www.langchain.com)              | Framework para orquestar LLMs con datos externos   |
| **Backend API**           | [FastAPI](https://fastapi.tiangolo.com/)            | API moderna en Python                              |
| **Frontend**              | HTML + JavaScript vanilla                           | Chat minimalista para interacciÃ³n con el asistente |

---

## ğŸ§© Flujo tÃ©cnico del sistema

1. El usuario formula una pregunta en lenguaje natural.
2. El LLM interpreta la intenciÃ³n y genera una **consulta Cypher**.
3. La consulta se ejecuta sobre Neo4j para recuperar informaciÃ³n.
4. El LLM integra esos resultados y genera una respuesta contextualizada.
5. FastAPI devuelve la respuesta al cliente web.

---

## ğŸ§ª Pruebas sugeridas

1. **Consulta simple:**
   â€œÂ¿QuÃ© cafÃ©s disponibles provienen de Colombia?â€
2. **Inferencia combinada:**
   â€œÂ¿QuÃ© mÃ©todo es ideal para un cafÃ© de proceso natural?â€
3. **Receta detallada:**
   â€œMostrame la receta recomendada para pour-over, incluyendo el agua.â€

---

## ğŸš€ Extensiones posibles

* Mostrar el **Cypher generado** y su resultado en la interfaz web.
* Agregar **logging** de preguntas y respuestas (historial de conversaciÃ³n).
* Incluir un **mÃ³dulo de recomendaciones** (â€œÂ¿QuÃ© cafÃ© me sugerÃ­s si me gusta el sabor floral?â€).
* Entrenar un modelo mÃ¡s liviano local (ej. **Mistral 7B**, **Gemma 7B**) para reducir latencia.
* Desplegar con **Docker Compose** integrando Neo4j + API + UI.

---

## ğŸ“œ Licencia

Este proyecto es de carÃ¡cter acadÃ©mico y educativo, desarrollado para la **Unidad 4 del curso de Inteligencia Artificial (PI5)**.
Su cÃ³digo puede reutilizarse libremente con fines de aprendizaje o demostraciÃ³n.

---

## ğŸ‘¨â€ğŸ’» Autor

**Diego PÃ¡ez**
Estudiante de IngenierÃ­a en Sistemas â€“ Argentina
Proyecto PI5 Â· Unidad 4 â€“ *IntegraciÃ³n de LLM Open Source con Grafo de Conocimiento*
2025

---
